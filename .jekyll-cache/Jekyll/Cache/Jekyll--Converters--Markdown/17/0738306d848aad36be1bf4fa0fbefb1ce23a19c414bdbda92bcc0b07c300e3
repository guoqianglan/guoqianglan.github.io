I"É(<p>In this post, I will show you how to deploy Kubernetes OpenStack.
More specifically, <a href="https://github.com/kubernetes-sigs/kubespray">Kubespary</a> with 
<a href="https://github.com/kubernetes-sigs/kubespray/tree/master/contrib/terraform">Terraform suport</a> will be applied to simplify the deployment.</p>

<h2 id="status">Status</h2>

<ul>
  <li><em>Local:</em> Ubuntu WSL system (Any Linux system should work as well)</li>
  <li><em>Cloud:</em> Persistent zone belong to <a href="https://arbutus.cloud.computecanada.ca/">Compute Canada Cloud, Arbhutus</a> 
(Other clouds based on OpenStack should work following this tutorial as well)</li>
</ul>

<h2 id="requirements">Requirements</h2>

<ul>
  <li>
    <p><em>Local:</em></p>

    <ol>
      <li>Create a new python virtual environment, e.g., â€˜openstack_envâ€™, activate it, and install openstackclient.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>virtualenv <span class="nt">--python</span><span class="o">=</span>python3 <span class="nb">env</span>/openstack_env
<span class="nb">source env</span>/openstack_env/bin/activate
pip <span class="nb">install </span>python-openstackclient
</code></pre></div>        </div>
      </li>
      <li>Install the dependencies of Kubespary.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/kubernetes-sigs/kubespray
<span class="nb">cd </span>kubespray
pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div>        </div>
      </li>
      <li><a href="https://www.terraform.io/intro/getting-started/install.html">Install Terraform 0.12</a> or later.</li>
      <li>Download the OpenStack RC File from your cloud provider and load it.
<img src="/images/blog_kube_jhub/download_rc_file.png" alt="_config.yml" />
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">source</span> &lt;your_project_name&gt;-openrc.sh
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ul>

<h2 id="setup-cluster">Setup cluster</h2>

<p>In kubespary directory, exectucate following commands.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">CLUSTER</span><span class="o">=</span>my-kube
  <span class="nb">cp</span> <span class="nt">-LRp</span> contrib/terraform/openstack/sample-inventory <span class="se">\</span>
  inventory/<span class="nv">$CLUSTER</span>
  <span class="nb">cd </span>inventory/<span class="nv">$CLUSTER</span>
  <span class="nb">ln</span> <span class="nt">-s</span> ../../contrib/terraform/openstack/hosts
  <span class="nb">ln</span> <span class="nt">-s</span> ../../contrib
</code></pre></div></div>
<p>Edit the cluster variable file, <code class="highlighter-rouge">inventory/$CLUSTER/cluster.tfvars</code>.</p>

<p>For example:</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># your Kubernetes cluster name here</span>
<span class="s">cluster_name = "k8s-cluster"</span>

<span class="c1"># list of availability zones available in your OpenStack cluster</span>
<span class="s">az_list = ["Persistent_01", "Persistent_02"]</span>
<span class="s">az_list_node = ["Persistent_01", "Persistent_02"]</span>

<span class="s">dns_nameservers=["100.125.4.25", "8.8.8.8"]</span>

<span class="c1"># SSH key to use for access to nodes</span>
<span class="s">public_key_path = "~/.ssh/id_rsa.pub"</span>

<span class="c1"># image to use for bastion, masters, standalone etcd instances, and nodes</span>
<span class="s">image = "CentOS-7-x64-2019-07"</span>

<span class="c1"># user on the node (ex. core on Container Linux, ubuntu on Ubuntu, etc.)</span>
<span class="s">ssh_user = "centos"</span>

<span class="c1"># 0|1 bastion nodes</span>
<span class="s">number_of_bastions = </span><span class="m">0</span>
<span class="s">flavor_bastion = "448319d3-2417-4eb1-9da2-63a2fdbc23f6"</span>

<span class="c1"># standalone etcds</span>
<span class="s">number_of_etcd = </span><span class="m">0</span>
<span class="s">flavor_etcd = "448319d3-2417-4eb1-9da2-63a2fdbc23f6"</span>

<span class="c1"># masters</span>
<span class="s">number_of_k8s_masters = </span><span class="m">1</span>

<span class="s">number_of_k8s_masters_no_etcd = </span><span class="m">0</span>

<span class="s">number_of_k8s_masters_no_floating_ip = </span><span class="m">0</span>

<span class="s">number_of_k8s_masters_no_floating_ip_no_etcd = </span><span class="m">0</span>

<span class="s">flavor_k8s_master = "448319d3-2417-4eb1-9da2-63a2fdbc23f6"</span>

<span class="c1"># nodes</span>
<span class="s">number_of_k8s_nodes = </span><span class="m">0</span>

<span class="s">number_of_k8s_nodes_no_floating_ip = </span><span class="m">4</span>

<span class="s">flavor_k8s_node = "448319d3-2417-4eb1-9da2-63a2fdbc23f6"</span>

<span class="c1"># GlusterFS</span>
<span class="c1"># either 0 or more than one</span>
<span class="c1"># number_of_gfs_nodes_no_floating_ip = 1</span>
<span class="c1"># gfs_volume_size_in_gb = 500</span>
<span class="c1"># Container Linux does not support GlusterFS</span>
<span class="s">image_gfs = "CentOS-7-x64-2019-07"</span>
<span class="c1"># May be different from other nodes</span>
<span class="s">ssh_user_gfs = "centos"</span>
<span class="s">flavor_gfs_node = "448319d3-2417-4eb1-9da2-63a2fdbc23f6"</span>

<span class="c1"># networking</span>
<span class="s">network_name = "k8s-network"</span>

<span class="s">external_net = "6621bf61-6094-4b24-a9a0-f5794c3a881e"</span>

<span class="s">subnet_cidr = "192.168.147.0/24"</span>

<span class="s">floatingip_pool = "Public-Network"</span>

<span class="s">bastion_allowed_remote_ips = ["0.0.0.0/0"]</span>

</code></pre></div></div>
<p>To start the Terraform deployment, you need to install some plugins using command as follows.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform init contrib/terraform/openstack
</code></pre></div></div>
<p>Start to build the cluster.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform apply -var-file=cluster.tfvars ../../contrib/terraform/openstack
</code></pre></div></div>
<p>If it is finished successfully, you will get output as follows.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Apply complete! Resources: 5 added, 0 changed, 0 destroyed.

Outputs:

bastion_fips = []
floating_network_id = 6621bf61-****************
k8s_master_fips = [
  "206.**.**.***",
]
k8s_node_fips = []
private_subnet_id = dfa59b71-**************
router_id = cf695cfb-******************
</code></pre></div></div>
<p>Then go back to the kubespary root directory. Try if ansible can successfully reach our clusters using</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ansible -i inventory/my-kube/hosts -m ping all
</code></pre></div></div>
<p>If all of the nodes are accessible, the output would look like
<img src="/images/blog_kube_jhub/ansible_ping_success.png" alt="_config.yml" /></p>

<p><strong>Note</strong>:</p>

<ul>
  <li><em>If the cluster is unreachable, please open additional TCP port 22 for SSH  then try again.</em></li>
</ul>

<p>Then letâ€™s see how to build Kubernetes on this cluster. Some additional configurations need to be modified.</p>

<ol>
  <li>
    <p>In <code class="highlighter-rouge">inventory/$CLUSTER/group_vars/all/all.yml</code>, set up <code class="highlighter-rouge">cloud_provider: openstack</code></p>
  </li>
  <li>
    <p>In <code class="highlighter-rouge">inventory/$CLUSTER/group_vars/k8s-cluster/k8s-cluster.yml</code>, set up <code class="highlighter-rouge">kube_network_plugin: flannel</code>, <code class="highlighter-rouge">resolvconf_mode: docker_dns</code> and <code class="highlighter-rouge">use_access_ip: 0</code></p>
  </li>
  <li>
    <p>In <code class="highlighter-rouge">inventory/$CLUSTER/group_vars/k8s-cluster/addons.yml</code> set up <code class="highlighter-rouge">helm_enabled: true</code></p>
  </li>
</ol>

<p><strong>Note</strong>:</p>
<ul>
  <li>If you failed to pinging float ip (<code class="highlighter-rouge">ping &lt;float_ip&gt;</code>), please open ICMP any port and then try again.</li>
</ul>

<p>Make sure you have good internet connection, or it is very easy to get timeout exception when you run the ansible playbook.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ansible-playbook --become -i inventory/$CLUSTER/hosts cluster.yml
</code></pre></div></div>
<ul>
  <li>If you failed to pass the etcd cluster healthy check, you may need to open port, TCP 2379. If it doesnâ€™t help, you would need login the master node 
and run commamd, <code class="highlighter-rouge">sudo chmod 755 -R /etc/ssl/etcd</code>. After that, you can check the healthy status by running
<code class="highlighter-rouge">etcdctl --endpoints https://&lt;master_ip&gt;:2379 --ca-file=/etc/ssl/etcd/ssl/ca.pem --cert-file=/etc/ssl/etcd/ssl/member-k8s-cluster-k8s-master-1.pem --key-file=/etc/ssl/etcd/ssl/member-k8s-cluster-k8s-master-1-key.pem cluster-health</code></li>
</ul>

<p>All done! please login in your master node and try to run <code class="highlighter-rouge">kubectl get nodes</code>, it should show the output like this
<img src="/images/blog_kube_jhub/kubectl_get_nodes.png" alt="_config.yml" /></p>

<p>Otherwise, if it return error message, 
<code class="highlighter-rouge">"The connection to the server localhost:8080 was refused - did you specify the right host or port?"</code>, 
please try to set up $KUBECONFIG using following command,</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo cp /etc/kubernetes/admin.conf $HOME/ &amp;&amp; sudo chown $(id -u):$(id -g) $HOME/admin.conf &amp;&amp; export KUBECONFIG=$HOME/admin.conf
</code></pre></div></div>
<p>Then you can try again.</p>

<p>In the future, if you restart your master node, you may need to restart the Kubernetes by running</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo systemctl restart kubelet.service
</code></pre></div></div>

<p><img src="/images/academic_computing.png" alt="_config.yml" /></p>
:ET